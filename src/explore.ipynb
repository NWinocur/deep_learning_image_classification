{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ GPU is available to Torch\n",
                        "GPU name: NVIDIA GeForce RTX 3080 Ti\n",
                        "GPU name: NVIDIA GeForce RTX 3070\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(\"‚úÖ GPU is available to Torch\")\n",
                "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU name: {torch.cuda.get_device_name(1)}\")\n",
                "else:\n",
                "    print(\"‚ùå GPU is NOT available to Torch\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 04:51:35.843958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1748076697.146029   46070 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1748076697.480535   46070 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1748076700.174584   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174623   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174625   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174627   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-05-24 04:51:40.458071: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîç TensorFlow build info:\n",
                        "OrderedDict([('cpu_compiler', '/usr/lib/llvm-18/bin/clang'), ('cuda_compute_capabilities', ['sm_60', 'sm_70', 'sm_80', 'sm_89', 'compute_90']), ('cuda_version', '12.5.1'), ('cudnn_version', '9'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False)])\n",
                        "/device:CPU:0 - CPU\n",
                        "/device:GPU:0 - GPU\n",
                        "/device:GPU:1 - GPU\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "I0000 00:00:1748076791.906539   46070 gpu_device.cc:2019] Created device /device:GPU:0 with 9446 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
                        "I0000 00:00:1748076791.915298   46070 gpu_device.cc:2019] Created device /device:GPU:1 with 5490 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "USE_BOTH_GPUS = True\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from tensorflow.python.client import device_lib\n",
                "\n",
                "print(\"üîç TensorFlow build info:\")\n",
                "print(tf.sysconfig.get_build_info())\n",
                "\n",
                "devices = device_lib.list_local_devices()\n",
                "for d in devices:\n",
                "    print(f\"{d.name} - {d.device_type}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert tf.config.list_physical_devices(\"GPU\"), \"‚ùå No GPU detected by TensorFlow\"\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Image loading and preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'os' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m USE_BOTH_GPUS \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_VISIBLE_DEVICES\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0,1\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m USE_BOTH_GPUS \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTF_GPU_ALLOCATOR\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda_malloc_async\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "USE_BOTH_GPUS = True\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:01:56.790553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1748080917.962148   93323 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1748080918.265416   93323 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1748080920.721608   93323 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748080920.721644   93323 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748080920.721646   93323 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748080920.721648   93323 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-05-24 06:02:01.014261: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "from tensorflow.keras import mixed_precision\n",
                "\n",
                "IMAGE_SIZE = 128  # allows choosing smaller than 200 to deal with memory constraints\n",
                "BATCH_SIZE = 32\n",
                "DATA_SUBSET = 5000  # allows choosing fewer than entirety of available photos for less memory & faster (albeit underfitting) training\n",
                "TRAIN_DIR = \"../data/raw/train/\"\n",
                "TEST_DIR = \"../data/raw/test1/\"\n",
                "\n",
                "mixed_precision.set_global_policy(\"mixed_float16\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "\n",
                "# prevent TensorFlow from preallocating all memory up front:\n",
                "gpus = tf.config.list_physical_devices(\"GPU\")\n",
                "for gpu in gpus:\n",
                "    tf.config.experimental.set_memory_growth(gpu, True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import cv2\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from sklearn.model_selection import train_test_split\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "# Directory with images\n",
                "filenames = sorted(os.listdir(TRAIN_DIR))[:DATA_SUBSET]\n",
                "labels = [0 if fname.startswith(\"dog\") else 1 for fname in filenames]\n",
                "\n",
                "# Full paths\n",
                "image_paths = [os.path.join(TRAIN_DIR, fname) for fname in filenames]\n",
                "\n",
                "# Create TensorFlow Dataset\n",
                "path_ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
                "\n",
                "\n",
                "def list_images_and_labels(directory, limit=None):\n",
                "    filenames = sorted(os.listdir(directory))\n",
                "    if limit:\n",
                "        filenames = filenames[:limit]\n",
                "    paths = [os.path.join(directory, fname) for fname in filenames]\n",
                "    labels = [0 if fname.startswith(\"dog\") else 1 for fname in filenames]\n",
                "    return paths, labels\n",
                "\n",
                "\n",
                "train_paths, train_labels = list_images_and_labels(TRAIN_DIR, limit=DATA_SUBSET)\n",
                "test_paths, test_labels = list_images_and_labels(\n",
                "    TEST_DIR, limit=int(DATA_SUBSET * 0.25)\n",
                ")\n",
                "\n",
                "\n",
                "# Load, decode, resize, normalize images\n",
                "def process_image(path, label):\n",
                "    image = tf.io.read_file(path)\n",
                "    image = tf.image.decode_jpeg(image, channels=3)\n",
                "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
                "    image = tf.cast(image, tf.float32) / 255.0\n",
                "    return image, tf.one_hot(label, depth=2)\n",
                "\n",
                "\n",
                "# create datasets\n",
                "train_ds = (\n",
                "    tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
                "    .map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    .shuffle(buffer_size=len(train_paths))\n",
                "    .batch(BATCH_SIZE)\n",
                "    .prefetch(tf.data.AUTOTUNE)\n",
                ")\n",
                "\n",
                "valid_ds = (\n",
                "    tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
                "    .map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    .batch(BATCH_SIZE)\n",
                "    .prefetch(tf.data.AUTOTUNE)\n",
                ")\n",
                "\n",
                "# Map preprocessing function\n",
                "# ds = path_ds.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
                "\n",
                "\n",
                "def train_cat_dog_model(\n",
                "    train_generator,\n",
                "    valid_generator,\n",
                "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
                "    num_classes=2,\n",
                "    epochs=30,\n",
                "):\n",
                "    # Strategy for multi-GPU support\n",
                "    strategy = tf.distribute.MirroredStrategy()\n",
                "    print(f\"‚úÖ Using {strategy.num_replicas_in_sync} GPU(s)\")\n",
                "\n",
                "    with strategy.scope():\n",
                "        model = tf.keras.Sequential(\n",
                "            [\n",
                "                tf.keras.layers.Input(shape=input_shape),\n",
                "                tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
                "                tf.keras.layers.MaxPooling2D(),\n",
                "                tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
                "                tf.keras.layers.MaxPooling2D(),\n",
                "                tf.keras.layers.Flatten(),\n",
                "                tf.keras.layers.Dense(512, activation=\"relu\"),\n",
                "                tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
                "            ]\n",
                "        )\n",
                "        model.compile(\n",
                "            optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
                "        )\n",
                "\n",
                "    callbacks = [\n",
                "        tf.keras.callbacks.ModelCheckpoint(\n",
                "            \"checkpoints/best_model.keras\", save_best_only=True, monitor=\"val_accuracy\"\n",
                "        ),\n",
                "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
                "    ]\n",
                "\n",
                "    history = model.fit(\n",
                "        train_ds, validation_data=valid_ds, epochs=epochs, callbacks=callbacks\n",
                "    )\n",
                "    return model, history\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
                        "‚úÖ Using 1 GPU(s)\n",
                        "Epoch 1/10\n",
                        "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 88ms/step - accuracy: 0.9643 - loss: 0.0279 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
                        "Epoch 2/10\n",
                        "\u001b[1m 68/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m11s\u001b[0m 126ms/step - accuracy: 1.0000 - loss: 1.1921e-07"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:00:08.053117: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
                        "Epoch 3/10\n",
                        "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
                        "Epoch 4/10\n",
                        "\u001b[1m157/157\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n"
                    ]
                }
            ],
            "source": [
                "model, history = train_cat_dog_model(\n",
                "    train_generator=train_ds,\n",
                "    valid_generator=valid_ds,\n",
                "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
                "    epochs=10,\n",
                ")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.17"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
