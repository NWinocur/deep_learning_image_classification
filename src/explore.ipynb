{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ GPU is available to Torch\n",
                        "GPU name: NVIDIA GeForce RTX 3080 Ti\n",
                        "GPU name: NVIDIA GeForce RTX 3070\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(\"‚úÖ GPU is available to Torch\")\n",
                "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU name: {torch.cuda.get_device_name(1)}\")\n",
                "else:\n",
                "    print(\"‚ùå GPU is NOT available to Torch\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 04:51:35.843958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1748076697.146029   46070 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1748076697.480535   46070 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1748076700.174584   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174623   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174625   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174627   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-05-24 04:51:40.458071: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîç TensorFlow build info:\n",
                        "OrderedDict([('cpu_compiler', '/usr/lib/llvm-18/bin/clang'), ('cuda_compute_capabilities', ['sm_60', 'sm_70', 'sm_80', 'sm_89', 'compute_90']), ('cuda_version', '12.5.1'), ('cudnn_version', '9'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False)])\n",
                        "/device:CPU:0 - CPU\n",
                        "/device:GPU:0 - GPU\n",
                        "/device:GPU:1 - GPU\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "I0000 00:00:1748076791.906539   46070 gpu_device.cc:2019] Created device /device:GPU:0 with 9446 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
                        "I0000 00:00:1748076791.915298   46070 gpu_device.cc:2019] Created device /device:GPU:1 with 5490 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from tensorflow.python.client import device_lib\n",
                "\n",
                "print(\"üîç TensorFlow build info:\")\n",
                "print(tf.sysconfig.get_build_info())\n",
                "\n",
                "devices = device_lib.list_local_devices()\n",
                "for d in devices:\n",
                "    print(f\"{d.name} - {d.device_type}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert tf.config.list_physical_devices(\"GPU\"), \"‚ùå No GPU detected by TensorFlow\"\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Image loading and preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 05:48:49.474074: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1748080131.017804   79178 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1748080131.400951   79178 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1748080134.364654   79178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748080134.364682   79178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748080134.364685   79178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748080134.364686   79178 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-05-24 05:48:54.744680: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "\n",
                "# prevent TensorFlow from preallocating all memory up front:\n",
                "gpus = tf.config.list_physical_devices(\"GPU\")\n",
                "for gpu in gpus:\n",
                "    tf.config.experimental.set_memory_growth(gpu, True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from tensorflow.keras import mixed_precision\n",
                "\n",
                "mixed_precision.set_global_policy(\"mixed_float16\")\n",
                "\n",
                "IMAGE_SIZE = 128  # allows choosing smaller than 200 to deal with memory constraints\n",
                "BATCH_SIZE = 32\n",
                "DATA_SUBSET = 5000  # allows choosing fewer than entirety of available photos for less memory & faster (albeit underfitting) training\n",
                "TRAIN_DIR = \"../data/raw/train/\"\n",
                "TEST_DIR = \"../data/raw/test1/\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "I0000 00:00:1748079334.348706   74294 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
                        "I0000 00:00:1748079334.352335   74294 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9536 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import cv2\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from sklearn.model_selection import train_test_split\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "# Directory with images\n",
                "filenames = sorted(os.listdir(TRAIN_DIR))[:DATA_SUBSET]\n",
                "labels = [0 if fname.startswith(\"dog\") else 1 for fname in filenames]\n",
                "\n",
                "# Full paths\n",
                "image_paths = [os.path.join(TRAIN_DIR, fname) for fname in filenames]\n",
                "\n",
                "# Create TensorFlow Dataset\n",
                "path_ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
                "\n",
                "\n",
                "def list_images_and_labels(directory, limit=None):\n",
                "    filenames = sorted(os.listdir(directory))\n",
                "    if limit:\n",
                "        filenames = filenames[:limit]\n",
                "    paths = [os.path.join(directory, fname) for fname in filenames]\n",
                "    labels = [0 if fname.startswith(\"dog\") else 1 for fname in filenames]\n",
                "    return paths, labels\n",
                "\n",
                "\n",
                "train_paths, train_labels = list_images_and_labels(TRAIN_DIR, limit=DATA_SUBSET)\n",
                "test_paths, test_labels = list_images_and_labels(\n",
                "    TEST_DIR, limit=int(DATA_SUBSET * 0.25)\n",
                ")\n",
                "\n",
                "\n",
                "# Load, decode, resize, normalize images\n",
                "def process_image(path, label):\n",
                "    image = tf.io.read_file(path)\n",
                "    image = tf.image.decode_jpeg(image, channels=3)\n",
                "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
                "    image = tf.cast(image, tf.float32) / 255.0\n",
                "    return image, tf.one_hot(label, depth=2)\n",
                "\n",
                "\n",
                "# create datasets\n",
                "train_ds = (\n",
                "    tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
                "    .map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    .shuffle(buffer_size=len(train_paths))\n",
                "    .batch(BATCH_SIZE)\n",
                "    .prefetch(tf.data.AUTOTUNE)\n",
                ")\n",
                "\n",
                "valid_ds = (\n",
                "    tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
                "    .map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    .batch(BATCH_SIZE)\n",
                "    .prefetch(tf.data.AUTOTUNE)\n",
                ")\n",
                "\n",
                "# Map preprocessing function\n",
                "# ds = path_ds.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "ename": "",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                        "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                        "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                        "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
                "\n",
                "\n",
                "def train_cat_dog_model(\n",
                "    train_generator,\n",
                "    valid_generator,\n",
                "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
                "    num_classes=2,\n",
                "    epochs=30,\n",
                "):\n",
                "    # Strategy for multi-GPU support\n",
                "    strategy = tf.distribute.MirroredStrategy()\n",
                "    print(f\"‚úÖ Using {strategy.num_replicas_in_sync} GPU(s)\")\n",
                "\n",
                "    with strategy.scope():\n",
                "        model = tf.keras.Sequential(\n",
                "            [\n",
                "                tf.keras.layers.Input(shape=input_shape),\n",
                "                tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
                "                tf.keras.layers.MaxPooling2D(),\n",
                "                tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
                "                tf.keras.layers.MaxPooling2D(),\n",
                "                tf.keras.layers.Flatten(),\n",
                "                tf.keras.layers.Dense(512, activation=\"relu\"),\n",
                "                tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
                "            ]\n",
                "        )\n",
                "        model.compile(\n",
                "            optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
                "        )\n",
                "\n",
                "    callbacks = [\n",
                "        tf.keras.callbacks.ModelCheckpoint(\n",
                "            \"checkpoints/best_model.keras\", save_best_only=True, monitor=\"val_accuracy\"\n",
                "        ),\n",
                "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
                "    ]\n",
                "\n",
                "    history = model.fit(\n",
                "        train_ds, validation_data=valid_ds, epochs=epochs, callbacks=callbacks\n",
                "    )\n",
                "    return model, history\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
                        "‚úÖ Using 1 GPU(s)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/mnt/c/Users/Nick/git/deep_learning_image_classification/.venv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
                        "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîç Run `tensorboard --logdir=logs` to view training curves.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 05:35:49.099510: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 6823 of 10000\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 05:35:45.030344: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "Epoch 1/10\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 05:35:59.097341: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 8210 of 10000\n",
                        "2025-05-24 05:35:53.939569: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n",
                        "I0000 00:00:1748079354.059364   75544 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m1240/1250\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9938 - loss: 0.0105INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 05:36:53.098965: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "2025-05-24 05:36:53.099063: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]]\n",
                        "2025-05-24 05:36:53.336619: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: CANCELLED: GetNextFromShard was cancelled\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]] [type.googleapis.com/tensorflow.DerivedStatus='']\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Epoch 1: val_accuracy improved from -inf to 1.00000, saving model to checkpoints/best_model.keras\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 05:37:09.275116: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 16106127360 exceeds 10% of free system memory.\n"
                    ]
                }
            ],
            "source": [
                "model, history = train_cat_dog_model(\n",
                "    train_generator=train_ds,\n",
                "    valid_generator=valid_ds,\n",
                "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
                "    epochs=10,\n",
                ")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.17"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
