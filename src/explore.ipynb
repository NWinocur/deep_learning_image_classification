{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Explore here\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ GPU is available to Torch\n",
                        "GPU name: NVIDIA GeForce RTX 3080 Ti\n",
                        "GPU name: NVIDIA GeForce RTX 3070\n"
                    ]
                }
            ],
            "source": [
                "import torch\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    print(\"‚úÖ GPU is available to Torch\")\n",
                "    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"GPU name: {torch.cuda.get_device_name(1)}\")\n",
                "else:\n",
                "    print(\"‚ùå GPU is NOT available to Torch\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 04:51:35.843958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1748076697.146029   46070 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1748076697.480535   46070 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1748076700.174584   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174623   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174625   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748076700.174627   46070 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-05-24 04:51:40.458071: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîç TensorFlow build info:\n",
                        "OrderedDict([('cpu_compiler', '/usr/lib/llvm-18/bin/clang'), ('cuda_compute_capabilities', ['sm_60', 'sm_70', 'sm_80', 'sm_89', 'compute_90']), ('cuda_version', '12.5.1'), ('cudnn_version', '9'), ('is_cuda_build', True), ('is_rocm_build', False), ('is_tensorrt_build', False)])\n",
                        "/device:CPU:0 - CPU\n",
                        "/device:GPU:0 - GPU\n",
                        "/device:GPU:1 - GPU\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "I0000 00:00:1748076791.906539   46070 gpu_device.cc:2019] Created device /device:GPU:0 with 9446 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
                        "I0000 00:00:1748076791.915298   46070 gpu_device.cc:2019] Created device /device:GPU:1 with 5490 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "USE_BOTH_GPUS = True\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from tensorflow.python.client import device_lib\n",
                "\n",
                "print(\"üîç TensorFlow build info:\")\n",
                "print(tf.sysconfig.get_build_info())\n",
                "\n",
                "devices = device_lib.list_local_devices()\n",
                "for d in devices:\n",
                "    print(f\"{d.name} - {d.device_type}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "assert tf.config.list_physical_devices(\"GPU\"), \"‚ùå No GPU detected by TensorFlow\"\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Image loading and preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "USE_BOTH_GPUS = True\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:18:01.454959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
                        "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
                        "E0000 00:00:1748081882.206803  106228 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
                        "E0000 00:00:1748081882.529011  106228 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
                        "W0000 00:00:1748081885.494893  106228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748081885.494934  106228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748081885.494937  106228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "W0000 00:00:1748081885.494939  106228 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
                        "2025-05-24 06:18:05.813130: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
                        "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
                    ]
                }
            ],
            "source": [
                "from tensorflow.keras import mixed_precision\n",
                "\n",
                "IMAGE_SIZE = 200  # allows choosing smaller than 200 to deal with memory constraints\n",
                "BATCH_SIZE = 16\n",
                "DATA_SUBSET = 10000  # allows choosing fewer than entirety of available photos for less memory & faster (albeit underfitting) training\n",
                "TRAIN_DIR = \"../data/raw/train/\"\n",
                "TEST_DIR = \"../data/raw/test1/\"\n",
                "\n",
                "mixed_precision.set_global_policy(\"mixed_float16\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "\n",
                "# prevent TensorFlow from preallocating all memory up front:\n",
                "gpus = tf.config.list_physical_devices(\"GPU\")\n",
                "for gpu in gpus:\n",
                "    tf.config.experimental.set_memory_growth(gpu, True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "I0000 00:00:1748081942.146238  106228 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
                        "I0000 00:00:1748081942.150537  106228 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9536 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
                        "I0000 00:00:1748081942.158025  106228 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 1\n",
                        "I0000 00:00:1748081942.158357  106228 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 5564 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:02:00.0, compute capability: 8.6\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "import cv2\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from sklearn.model_selection import train_test_split\n",
                "from tensorflow.keras.utils import to_categorical\n",
                "\n",
                "# Directory with images\n",
                "filenames = sorted(os.listdir(TRAIN_DIR))[:DATA_SUBSET]\n",
                "labels = [0 if fname.startswith(\"dog\") else 1 for fname in filenames]\n",
                "\n",
                "# Full paths\n",
                "image_paths = [os.path.join(TRAIN_DIR, fname) for fname in filenames]\n",
                "\n",
                "# Create TensorFlow Dataset\n",
                "path_ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
                "\n",
                "\n",
                "def list_images_and_labels(directory, limit=None):\n",
                "    filenames = sorted(os.listdir(directory))\n",
                "    if limit:\n",
                "        filenames = filenames[:limit]\n",
                "    paths = [os.path.join(directory, fname) for fname in filenames]\n",
                "    labels = [0 if fname.startswith(\"dog\") else 1 for fname in filenames]\n",
                "    return paths, labels\n",
                "\n",
                "\n",
                "train_paths, train_labels = list_images_and_labels(TRAIN_DIR, limit=DATA_SUBSET)\n",
                "test_paths, test_labels = list_images_and_labels(\n",
                "    TEST_DIR, limit=int(DATA_SUBSET * 0.25)\n",
                ")\n",
                "\n",
                "\n",
                "# Load, decode, resize, normalize images\n",
                "def process_image(path, label):\n",
                "    image = tf.io.read_file(path)\n",
                "    image = tf.image.decode_jpeg(image, channels=3)\n",
                "    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n",
                "    image = tf.cast(image, tf.float32) / 255.0\n",
                "    return image, tf.one_hot(label, depth=2)\n",
                "\n",
                "\n",
                "# create datasets\n",
                "train_ds = (\n",
                "    tf.data.Dataset.from_tensor_slices((train_paths, train_labels))\n",
                "    .map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    .shuffle(buffer_size=len(train_paths))\n",
                "    .batch(BATCH_SIZE)\n",
                "    .prefetch(tf.data.AUTOTUNE)\n",
                ")\n",
                "\n",
                "valid_ds = (\n",
                "    tf.data.Dataset.from_tensor_slices((test_paths, test_labels))\n",
                "    .map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
                "    .batch(BATCH_SIZE)\n",
                "    .prefetch(tf.data.AUTOTUNE)\n",
                ")\n",
                "\n",
                "# Map preprocessing function\n",
                "# ds = path_ds.map(process_image, num_parallel_calls=tf.data.AUTOTUNE)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "\n",
                "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1\" if USE_BOTH_GPUS else \"0\"\n",
                "os.environ[\"TF_GPU_ALLOCATOR\"] = \"cuda_malloc_async\"\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras.models import Sequential\n",
                "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
                "from tensorflow.keras.optimizers import Adam\n",
                "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
                "\n",
                "\n",
                "def train_cat_dog_model(\n",
                "    train_generator,\n",
                "    valid_generator,\n",
                "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
                "    num_classes=2,\n",
                "    epochs=30,\n",
                "):\n",
                "    # Strategy for multi-GPU support\n",
                "    strategy = tf.distribute.MirroredStrategy()\n",
                "    print(f\"‚úÖ Using {strategy.num_replicas_in_sync} GPU(s)\")\n",
                "\n",
                "    with strategy.scope():\n",
                "        model = tf.keras.Sequential(\n",
                "            [\n",
                "                tf.keras.layers.Input(shape=input_shape),\n",
                "                tf.keras.layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
                "                tf.keras.layers.MaxPooling2D(),\n",
                "                tf.keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
                "                tf.keras.layers.MaxPooling2D(),\n",
                "                tf.keras.layers.Flatten(),\n",
                "                tf.keras.layers.Dense(256, activation=\"relu\"),\n",
                "                tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
                "            ]\n",
                "        )\n",
                "        model.compile(\n",
                "            optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
                "        )\n",
                "\n",
                "    callbacks = [\n",
                "        tf.keras.callbacks.ModelCheckpoint(\n",
                "            \"checkpoints/best_model.keras\", save_best_only=True, monitor=\"val_accuracy\"\n",
                "        ),\n",
                "        tf.keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True),\n",
                "    ]\n",
                "\n",
                "    history = model.fit(\n",
                "        train_ds, validation_data=valid_ds, epochs=epochs, callbacks=callbacks\n",
                "    )\n",
                "    return model, history\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
                        "‚úÖ Using 2 GPU(s)\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:19:18.582262: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 4995 of 10000\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:19:17.738259: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "Epoch 1/10\n",
                        "INFO:tensorflow:Collective all_reduce tensors: 8 all_reduces, num_devices = 2, group_size = 2, implementation = CommunicationImplementation.NCCL, num_packs = 1\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:19:33.611867: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 7266 of 10000\n",
                        "2025-05-24 06:19:29.973697: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n",
                        "I0000 00:00:1748081970.289589  107121 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
                        "I0000 00:00:1748081970.288927  107124 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m608/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - accuracy: 0.9971 - loss: 0.0079"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:21:09.793617: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "2025-05-24 06:21:09.793695: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]]\n",
                        "2025-05-24 06:21:09.794366: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
                        "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:21:14.107348: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 162ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
                        "Epoch 2/10\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:21:33.842860: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 4832 of 10000\n",
                        "2025-05-24 06:21:32.625284: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 151ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:23:07.185223: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]]\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Epoch 3/10\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:23:19.004468: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 5606 of 10000\n",
                        "2025-05-24 06:23:17.313068: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 152ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n",
                        "Epoch 4/10\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:25:04.203467: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] ShuffleDatasetV3:3: Filling up shuffle buffer (this may take a while): 3488 of 10000\n",
                        "2025-05-24 06:25:05.367930: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\u001b[1m625/625\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 156ms/step - accuracy: 1.0000 - loss: 1.1921e-07 - val_accuracy: 1.0000 - val_loss: 1.1921e-07\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-05-24 06:26:42.752805: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
                        "\t [[{{node MultiDeviceIteratorGetNextFromShard}}]]\n",
                        "\t [[RemoteCall]]\n"
                    ]
                }
            ],
            "source": [
                "model, history = train_cat_dog_model(\n",
                "    train_generator=train_ds,\n",
                "    valid_generator=valid_ds,\n",
                "    input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\n",
                "    epochs=10,\n",
                ")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.17"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
